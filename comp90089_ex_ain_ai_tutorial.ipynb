{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um2pyaJP3b_N"
   },
   "source": [
    "# Machine Learning Applications for Health\n",
    "# Tutorial: Interpretable Machine Learning with MIMIC-IV clinical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB0mWgUM3iKe"
   },
   "source": [
    "> ### Goal: Predict and Understand the mortality risk for Sepsis Cohort\n",
    "\n",
    "####Explainable Boosting Machine (EBM)\n",
    "\n",
    "\n",
    "* **Data** set: query the cohort in MIMIC-IV \n",
    "* Create the machine learning model with **interpretML library**\n",
    "* **Split** the dataset\n",
    "* **Fit** the model using the training data set\n",
    "* **Predict and Evaluate** the performance of the model using the testing set (unseen data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kppqAEUyNBVU"
   },
   "source": [
    "* InterpretML is an open-source Python package and the documentation can be found [here](https://interpret.ml/).\n",
    "* The preprint about the framework can be read [here,](https://arxiv.org/abs/1909.09223) and the GA2M paper [here.](https://www.cs.cornell.edu/~yinlou/papers/lou-kdd12.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEHRht-36bj2"
   },
   "source": [
    "### Set up the main **libraries**: interpret, numpy, pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_yIFY9u5zK-"
   },
   "outputs": [],
   "source": [
    "# !pip install interpret #Uncomment and run this cell to install interpretML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huZghbUb63Y6"
   },
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "from interpret import show\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Access data using Google BigQuery.\n",
    "from google.colab import auth\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None) ##This is only to show all columns when printing a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weFGJb7f1K-D"
   },
   "source": [
    "* Authenticate in the BigQuery platform. Define the function to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gbev8Mj06HS"
   },
   "outputs": [],
   "source": [
    "# authenticate\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMKOBlsz0777"
   },
   "outputs": [],
   "source": [
    "# Set up environment variables\n",
    "project_id = 'CHANGE-ME' ##Change only this variable with your project ID in BigQuery Platform.\n",
    "if project_id == 'CHANGE-ME': #No Need to change this one!\n",
    "  raise ValueError('You must change project_id to your GCP project.')\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
    "\n",
    "# Read data from BigQuery into pandas dataframes.\n",
    "def run_query(query, project_id=project_id):\n",
    "  return pd.io.gbq.read_gbq(\n",
    "      query,\n",
    "      project_id=project_id,\n",
    "      dialect='standard')\n",
    "\n",
    "# set the dataset\n",
    "dataset = 'mimiciv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrpjACnY79AK"
   },
   "source": [
    "## **Data set**\n",
    "We'll use a cohort derived from MIMIC-IV.\n",
    "\n",
    "* The query bellow is searching for the data in the **BigQuery Platform**.\n",
    "* We are retrieving patients with **Sepsis**: A life-threatening complication caused by the body's response to an infection. When your immune system goes into **overdrive in response to an infection**, sepsis may develop as a result\n",
    "* Further, we will join the Date of Death information, the age and gender from patients table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wfxeUfd09wU"
   },
   "outputs": [],
   "source": [
    "##We are retrieving patients using sepsis3 Table and joining it to patients Table.\n",
    "\n",
    "df = run_query(\"\"\"\n",
    "SELECT sep.subject_id,sep.sofa_score,sep.respiration,sep.coagulation,sep.liver,sep.cardiovascular,sep.cns,sep.renal,pt.dod,pt.anchor_age,pt.gender\n",
    "FROM `physionet-data.mimiciv_derived.sepsis3` as sep\n",
    "INNER JOIN `physionet-data.mimiciv_hosp.patients` as pt\n",
    "ON sep.subject_id = pt.subject_id\n",
    "ORDER BY subject_id\n",
    "\"\"\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJwgCxE3k3P"
   },
   "source": [
    "* We have been analysing this dataset since the beggining, so just recap what needs to be done: Check for missing values, transform categorical into numerical and verify the dtype of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ijM6sI13V02"
   },
   "outputs": [],
   "source": [
    "dataset = df.copy()\n",
    "\n",
    "#Replace Date of Death times with binary (0 or 1)\n",
    "dataset.loc[dataset['dod'].notna(),'dod'] = int(1)\n",
    "dataset.loc[dataset['dod'].isnull(),'dod'] = int(0)\n",
    "dataset['dod'] = dataset['dod'].astype(int)\n",
    "\n",
    "#Transform Gender column from Categorical Data to Binary:\n",
    "gender_categorical = pd.get_dummies(dataset['gender'])\n",
    "\n",
    "#Concatenate both Data frames:\n",
    "final_sepsis = pd.concat([dataset,gender_categorical], axis = 1)\n",
    "\n",
    "#Final Data set to work with:\n",
    "final_sepsis = final_sepsis.drop(['subject_id','gender'], axis = 1)\n",
    "print(final_sepsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeWCMd3N4Mn-"
   },
   "outputs": [],
   "source": [
    "#Check the final dtype of each column. Are they properly defined now? \n",
    "print(final_sepsis.info(),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c4JYspQ2grp"
   },
   "source": [
    "* Split the data set into Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpFsbmXR7fuY"
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "target = 'dod'\n",
    "X = final_sepsis.drop(labels = target, axis = 1) #Remove the target column from the dataset to create the independent(features) variables set\n",
    "y = final_sepsis[target]\n",
    "\n",
    "#Adjust the size of the testing set: we'll use 10% of the entire data. \n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGJlpnK48Snn"
   },
   "source": [
    "### Explainable Boosting Machine model\n",
    "\n",
    "* Glassbox models are designed to be completely interpretable, and often provide similar accuracy to state-of-the-art methods.\n",
    "* Can also provide explanations on a both global (overall behavior) and local (individual predictions) level.\n",
    "  * Global explanations are useful for understanding what a model finds important, as well as identifying potential flaws in its decision making\n",
    "* **Explainable Boosting Machine (EBM)** is a tree-based, cyclic gradient boosting Generalized Additive Model with automatic interaction detection. Read more about it [here.](https://interpret.ml/docs/ebm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyyBaLe78SyS"
   },
   "outputs": [],
   "source": [
    "ebm = ExplainableBoostingClassifier(random_state=1)\n",
    "classifier = ebm.fit(X_train, y_train)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxNQvHIyStcg"
   },
   "outputs": [],
   "source": [
    "## Accuracy of the Model in the training\n",
    "print(classifier.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRBYsOJCSP_D"
   },
   "source": [
    "### Evaluation of the EBM model with unseen data from the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOMNupvhRdug"
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "#Accuracy classification score\n",
    "acc = float(round(metrics.accuracy_score(y_test, predictions),3))\n",
    "\n",
    "#Compute the balanced accuracy.\n",
    "bacc = float(round(metrics.balanced_accuracy_score(y_test, predictions),3))\n",
    "\n",
    "#Compute the Matthews correlation coefficient (MCC)\n",
    "mcc = float(round(metrics.matthews_corrcoef(y_test, predictions),3))\n",
    "\n",
    "#Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "f1 = float(round(metrics.f1_score(y_test, predictions),3))\n",
    "\n",
    "#Show results as a DataFrame:\n",
    "results = {'Accuracy' : [acc], 'Balanced Accuracy' : [bacc], 'MCC' : [mcc], 'F1-Score' : [f1]}\n",
    "df_results = pd.DataFrame.from_dict(data = results, orient='columns')\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjv9USGjRMgk"
   },
   "source": [
    "### Let's Visualise the global model Behaviour with each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ymp1VkMcQ0pr"
   },
   "outputs": [],
   "source": [
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChwUtrWoRjp4"
   },
   "source": [
    "### Let's Visualise the local model Behaviour with some unseen examples from the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rjr7NsMlRj2H"
   },
   "outputs": [],
   "source": [
    "set_visualize_provider(InlineProvider()) #plot the output here\n",
    "ebm_local = ebm.explain_local(X_test[:5], y_test[:5])\n",
    "show(ebm_local)\n",
    "\n",
    "## To save the figure you must install orca library first (https://github.com/plotly/orca)\n",
    "#plotly_fig = ebm_local.visualize(0) # This is the plotly figure for visualization of the 0th datapoint's local explanation\n",
    "#plotly_fig.write_image(\"images/fig0.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VSrIxfcwOvz"
   },
   "source": [
    "* Discussion: How can you compare this result with the previous (Deep Learning with the same Sepsis data)?\n",
    "* What understanding can you grasp from the plots? \n",
    "* Which feature is contributing the most?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
